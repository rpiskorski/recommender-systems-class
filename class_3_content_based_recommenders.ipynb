{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "literary-toyota",
   "metadata": {},
   "source": [
    "# Content-based recommenders\n",
    "\n",
    "Content-based recommenders in their recommendations rely purely on the features of items. Conceptually it can be expressed as a model of the form (personalized):\n",
    "<center>\n",
    "$$\n",
    "    score \\sim (user, item\\_feature_1, item\\_feature_2, ..., item\\_feature_n)\n",
    "$$\n",
    "</center>\n",
    "or (not personalized)\n",
    "<center>\n",
    "$$\n",
    "    score \\sim (item\\_feature_1, item\\_feature_2, ..., item\\_feature_n)\n",
    "$$\n",
    "</center>\n",
    "\n",
    "    + Content-based recommenders do not suffer from the cold-start problem for new items.\n",
    "    - They do not use information about complex patterns of user-item interactions - what other similar users have already discovered and liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exciting-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-charleston",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "architectural-andrews",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of left interactions: 9692\n"
     ]
    }
   ],
   "source": [
    "ml_ratings_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"ratings.csv\")).rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "ml_movies_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"movies.csv\")).rename(columns={'movieId': 'item_id'})\n",
    "ml_df = pd.merge(ml_ratings_df, ml_movies_df, on='item_id')\n",
    "ml_df.head(10)\n",
    "\n",
    "display(HTML(ml_movies_df.head(10).to_html()))\n",
    "\n",
    "# Filter the data to reduce the number of movies\n",
    "rng = np.random.RandomState(seed=6789)\n",
    "# left_ids = rng.choice(ml_movies_df['item_id'], size=100, replace=False)\n",
    "left_ids = rng.choice(ml_movies_df['item_id'], size=1000, replace=False)\n",
    "\n",
    "ml_ratings_df = ml_ratings_df.loc[ml_ratings_df['item_id'].isin(left_ids)]\n",
    "ml_movies_df = ml_movies_df.loc[ml_movies_df['item_id'].isin(left_ids)]\n",
    "ml_df = ml_df.loc[ml_df['item_id'].isin(left_ids)]\n",
    "\n",
    "print(\"Number of left interactions: {}\".format(len(ml_ratings_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-renaissance",
   "metadata": {},
   "source": [
    "# Recommender class\n",
    "\n",
    "Remark: Docstrings written in reStructuredText (reST) used by Sphinx to automatically generate code documentation. It is also used by default by PyCharm (type triple quotes after defining a class or a method and hit enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cooperative-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': [-1] * n_recommendations,\n",
    "                                                 'score': [3.0] * n_recommendations})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-warehouse",
   "metadata": {},
   "source": [
    "# Evaluation measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-perspective",
   "metadata": {},
   "source": [
    "## Explicit feedback - ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-anderson",
   "metadata": {},
   "source": [
    "### RMSE - Root Mean Squared Error\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    RMSE = \\sqrt{\\frac{\\sum_{i}^N (\\hat{r}_i - r_i)^2}{N}}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\hat{r}_i$ are the predicted ratings and $r_i$ are the real ratings and $N$ is the number of items in the test set.\n",
    "\n",
    "    + Very well-behaved analytically and therefore extensively used to train models, especially neural networks.\n",
    "    - The scale of errors dependent on data which reduced comparability between different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entitled-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.33\n"
     ]
    }
   ],
   "source": [
    "def rmse(r_pred, r_real):\n",
    "    return np.sqrt(np.sum(np.power(r_pred - r_real, 2)) / len(r_pred))\n",
    "\n",
    "# Test\n",
    "\n",
    "print(\"RMSE = {:.2f}\".format(rmse(np.array([2.1, 1.2, 3.8, 4.2, 3.6]), np.array([3, 2, 4, 5, 1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dying-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRE = 0.7020\n"
     ]
    }
   ],
   "source": [
    "def mre(r_pred, r_real):\n",
    "    return 1 / len(r_pred) * np.sum(np.abs(r_pred - r_real) / np.abs(r_real))\n",
    "\n",
    "# Test\n",
    "\n",
    "print(\"MRE = {:.4f}\".format(mre(np.array([2.1, 1.2, 3.8, 4.2, 3.6]), np.array([3, 2, 4, 5, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-arrival",
   "metadata": {},
   "source": [
    "### MRE - Mean Relative Error\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    MRE = \\frac{1}{N} \\sum_{i}^N \\frac{|\\hat{r}_i - r_i|}{|r_i|}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\hat{r}_i$ are the predicted ratings and $r_i$ are the real ratings and $N$ is the number of items in the test set.\n",
    "\n",
    "    + Easily interpretable (average percentage error) and with a meaning understandable for business.\n",
    "    - Blows up when there are values close to zero among the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-contribution",
   "metadata": {},
   "source": [
    "### TRE - Total Relative Error\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    TRE = \\frac{\\sum_{i}^N |\\hat{r}_i - r_i|}{\\sum_{i}^N |r_i|}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\hat{r}_i$ are the predicted ratings and $r_i$ are the real ratings and $N$ is the number of items in the test set.\n",
    "\n",
    "    + Easily interpretable (total percentage error) and with a meaning understandable for business.\n",
    "    + Reliable even for very small predicted values.\n",
    "    - Does not distinguish between a case when one prediction is very bad and other are very good and a case when all predictions are mediocre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premium-trouble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRE = 0.3533\n"
     ]
    }
   ],
   "source": [
    "def tre(r_pred, r_real):\n",
    "    return np.sum(np.abs(r_pred - r_real)) / np.sum(np.abs(r_real))\n",
    "\n",
    "# Test\n",
    "\n",
    "print(\"TRE = {:.4f}\".format(tre(np.array([2.1, 1.2, 3.8, 4.2, 3.6]), np.array([3, 2, 4, 5, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-navigation",
   "metadata": {},
   "source": [
    "## Implicit feedback - binary indicators of interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-egypt",
   "metadata": {},
   "source": [
    "### HR@n - Hit Ratio \n",
    "How many hits did we score in the first n recommendations.\n",
    "<br/>\n",
    "<br/>\n",
    "<center>\n",
    "$$\n",
    "    \\text{HR@}n = \\frac{\\sum_{u} \\sum_{i \\in I_u} r_{u, i} \\cdot 1_{\\hat{D}_n(u)}(i)}{M}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where:\n",
    "  * $r_{u, i}$ is $1$ if there was an interaction between user $u$ and item $i$ in the test set and $0$ otherwise, \n",
    "  * $\\hat{D}_n$ is the set of the first $n$ recommendations for user $u$, \n",
    "  * $1_{\\hat{D}_n}(i)$ is $1$ if and only if $i \\in \\hat{D}_n$, otherwise it's equal to $0$,\n",
    "  * $M$ is the number of users.\n",
    "\n",
    "\n",
    "    + Easily interpretable.\n",
    "    - Does not take the rank of each recommendation into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "found-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@3 = 1.5000\n"
     ]
    }
   ],
   "source": [
    "def hr(recommendations, real_interactions, n=1):\n",
    "    \"\"\"\n",
    "    Assumes recommendations are ordered by user_id and then by score.\n",
    "    \"\"\"\n",
    "    # Transform real_interactions to a dict for a large speed-up\n",
    "    rui = defaultdict(lambda: 0)\n",
    "    \n",
    "    for idx, row in real_interactions.iterrows():\n",
    "        rui[(row['user_id'], row['item_id'])] = 1\n",
    "        \n",
    "    hr = 0.0\n",
    "    \n",
    "    previous_user_id = -1\n",
    "    rank = 0\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        if previous_user_id == row['user_id']:\n",
    "            rank += 1\n",
    "        else:\n",
    "            rank = 1\n",
    "            \n",
    "        if rank <= n:\n",
    "            hr += rui[(row['user_id'], row['item_id'])]\n",
    "#             print(\"hr \",hr)\n",
    "        \n",
    "        previous_user_id = row['user_id']\n",
    "    \n",
    "    hr /= len(recommendations['user_id'].unique())\n",
    "    \n",
    "    return hr\n",
    "\n",
    "    \n",
    "recommendations = pd.DataFrame(\n",
    "    [\n",
    "        [1, 13, 0.9],\n",
    "        [1, 45, 0.8],\n",
    "        [1, 22, 0.71],\n",
    "        [1, 77, 0.55],\n",
    "        [1, 9, 0.52],\n",
    "        [2, 11, 0.85],\n",
    "        [2, 13, 0.69],\n",
    "        [2, 25, 0.64],\n",
    "        [2, 6, 0.60],\n",
    "        [2, 77, 0.53]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id', 'score'])\n",
    "\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "real_interactions = pd.DataFrame(\n",
    "    [\n",
    "        [1, 45],\n",
    "        [1, 22],\n",
    "        [1, 77],\n",
    "        [2, 13],\n",
    "        [2, 77]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id'])\n",
    "\n",
    "display(HTML(real_interactions.to_html()))\n",
    "    \n",
    "print(\"HR@3 = {:.4f}\".format(hr(recommendations, real_interactions, n=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-munich",
   "metadata": {},
   "source": [
    "### NDCG@n - Normalized Discounted Cumulative Gain\n",
    "\n",
    "How many hits did we score in the first n recommendations discounted by the position of each recommendation.\n",
    "<br/>\n",
    "<br/>\n",
    "<center>\n",
    "$$\n",
    "    \\text{NDCG@}n = \\frac{\\sum_{u} \\sum_{i \\in I_u} \\frac{r_{u, i}}{log\\left(1 + v_{\\hat{D}_n(u)}(i)\\right)}}{M}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where:\n",
    "  * $r_{u, i}$ is $1$ if there was an interaction between user $u$ and item $i$ in the test set and $0$ otherwise, \n",
    "  * $\\hat{D}_n(u)$ is the set of the first $n$ recommendations for user $u$, \n",
    "  * $v_{\\hat{D}_n(u)}(i)$ is the position of item $i$ in recommendations $\\hat{D}_n$,\n",
    "  * $M$ is the number of users.\n",
    "\n",
    "\n",
    "    - Takes the rank of each recommendation into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floral-anatomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@3 = 0.8809\n"
     ]
    }
   ],
   "source": [
    "def ndcg(recommendations, real_interactions, n=1):\n",
    "    \"\"\"\n",
    "    Assumes recommendations are ordered by user_id and then by score.\n",
    "    \"\"\"\n",
    "    # Transform real_interactions to a dict for a large speed-up\n",
    "    rui = defaultdict(lambda: 0)\n",
    "    \n",
    "    for idx, row in real_interactions.iterrows():\n",
    "        rui[(row['user_id'], row['item_id'])] = 1\n",
    "        \n",
    "    ndcg = 0.0\n",
    "    \n",
    "    previous_user_id = -1\n",
    "    rank = 0\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        if previous_user_id == row['user_id']:\n",
    "            rank += 1\n",
    "        else:\n",
    "            rank = 1\n",
    "            \n",
    "        if rank <= n:\n",
    "            ndcg += rui[(row['user_id'], row['item_id'])] / np.log2(1 + rank)\n",
    "        \n",
    "        previous_user_id = row['user_id']\n",
    "    \n",
    "    ndcg /= len(recommendations['user_id'].unique())\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "    \n",
    "recommendations = pd.DataFrame(\n",
    "    [\n",
    "        [1, 13, 0.9],\n",
    "        [1, 45, 0.8],\n",
    "        [1, 22, 0.71],\n",
    "        [1, 77, 0.55],\n",
    "        [1, 9, 0.52],\n",
    "        [2, 11, 0.85],\n",
    "        [2, 13, 0.69],\n",
    "        [2, 25, 0.64],\n",
    "        [2, 6, 0.60],\n",
    "        [2, 77, 0.53]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id', 'score'])\n",
    "\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "real_interactions = pd.DataFrame(\n",
    "    [\n",
    "        [1, 45],\n",
    "        [1, 22],\n",
    "        [1, 77],\n",
    "        [2, 13],\n",
    "        [2, 77]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id'])\n",
    "\n",
    "display(HTML(real_interactions.to_html()))\n",
    "    \n",
    "print(\"NDCG@3 = {:.4f}\".format(ndcg(recommendations, real_interactions, n=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-baltimore",
   "metadata": {},
   "source": [
    "# Testing routines (offline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-elevation",
   "metadata": {},
   "source": [
    "## Train and test set split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-blackjack",
   "metadata": {},
   "source": [
    "### Explicit feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "negative-cigarette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MRE</th>\n",
       "      <th>TRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseRecommender</td>\n",
       "      <td>1.170155</td>\n",
       "      <td>0.349264</td>\n",
       "      <td>0.271796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_train_test_split_explicit(recommender, interactions_df, items_df, seed=6789):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    # Split the dataset into train and test\n",
    "    \n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    interactions_df_train = interactions_df.iloc[shuffle[:split_index]]\n",
    "    interactions_df_test = interactions_df.iloc[shuffle[split_index:]]\n",
    "    \n",
    "#     print(interactions_df_test)\n",
    "    \n",
    "    # Train the recommender\n",
    "    \n",
    "    recommender.fit(interactions_df_train, None, items_df)\n",
    "    \n",
    "    # Gather predictions\n",
    "    \n",
    "    r_pred = []\n",
    "    \n",
    "    for idx, row in interactions_df_test.iterrows():\n",
    "        users_df = pd.DataFrame([row['user_id']], columns=['user_id'])\n",
    "        eval_items_df = pd.DataFrame([row['item_id']], columns=['item_id'])\n",
    "        eval_items_df = pd.merge(eval_items_df, items_df, on='item_id')\n",
    "        recommendations = recommender.recommend(users_df, eval_items_df, n_recommendations=1)\n",
    "        \n",
    "        r_pred.append(recommendations.iloc[0]['score'])\n",
    "    \n",
    "    # Gather real ratings\n",
    "    \n",
    "    r_real = np.array(interactions_df_test['rating'].tolist())\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    \n",
    "    return rmse(r_pred, r_real), mre(r_pred, r_real), tre(r_pred, r_real)\n",
    "\n",
    "recommender = Recommender()\n",
    "\n",
    "results = [['BaseRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fundamental-driver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id\n",
       "0        533\n",
       "1         40\n",
       "2        184\n",
       "3        600\n",
       "4        486\n",
       "..       ...\n",
       "373      447\n",
       "374      414\n",
       "375      511\n",
       "376      269\n",
       "377      283\n",
       "\n",
       "[378 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "# ml_ratings_df user_id ; item_id ; rating ; timestamp\n",
    "# ml_movies_df item_id ; title ; genres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-croatia",
   "metadata": {},
   "source": [
    "### Implicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-enclosure",
   "metadata": {},
   "source": [
    "**Task 1.** Implement the following method for train-test split evaluation for implicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "considerable-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.044743</td>\n",
       "      <td>0.058166</td>\n",
       "      <td>0.09396</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.038368</td>\n",
       "      <td>0.049966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_train_test_split_implicit(recommender, interactions_df, items_df, seed=6789):\n",
    "    # Write your code here\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    interactions_df_train = interactions_df.iloc[shuffle[:split_index]]\n",
    "    interactions_df_test = interactions_df.iloc[shuffle[split_index:]]\n",
    "    \n",
    "    # Train the recommender\n",
    "    \n",
    "    recommender.fit(interactions_df_train, None, items_df)\n",
    "\n",
    "    \n",
    "    r_pred = []\n",
    "    \n",
    "    hr_1 = []\n",
    "    hr_3 = []\n",
    "    hr_5 = []\n",
    "    hr_10 = []\n",
    "    ndcg_1 = []\n",
    "    ndcg_3 = []\n",
    "    ndcg_5 = []\n",
    "    ndcg_10 = []\n",
    "    \n",
    "    users_un = pd.DataFrame(interactions_df_test.loc[:,'user_id'].unique(),columns=['user_id'])\n",
    "    \n",
    "    k=1\n",
    "    for idx, row in users_un.iterrows():\n",
    "        print(k)\n",
    "        k+=1\n",
    "        users_df = pd.DataFrame([row['user_id']], columns=['user_id'])\n",
    "        recommendations = recommender.recommend(users_df, items_df, n_recommendations=10)\n",
    "\n",
    "        \n",
    "        hr_1.append(hr(recommendations, interactions_df_test, n=1))\n",
    "        hr_3.append(hr(recommendations, interactions_df_test, n=3))\n",
    "        hr_5.append(hr(recommendations, interactions_df_test, n=5))\n",
    "        hr_10.append(hr(recommendations, interactions_df_test, n=10))\n",
    "        ndcg_1.append(ndcg(recommendations, interactions_df_test, n=1))\n",
    "        ndcg_3.append(ndcg(recommendations, interactions_df_test, n=3))\n",
    "        ndcg_5.append(ndcg(recommendations, interactions_df_test, n=5))\n",
    "        ndcg_10.append(ndcg(recommendations, interactions_df_test, n=10))\n",
    "\n",
    "        \n",
    "    hr_1 = np.mean(hr_1)\n",
    "    hr_3 = np.mean(hr_3)\n",
    "    hr_5 = np.mean(hr_5)\n",
    "    hr_10 = np.mean(hr_10)\n",
    "    ndcg_1 = np.mean(ndcg_1)\n",
    "    ndcg_3 = np.mean(ndcg_3)\n",
    "    ndcg_5 = np.mean(ndcg_5)\n",
    "    ndcg_10 = np.mean(ndcg_10)\n",
    "    \n",
    "    return hr_1, hr_3, hr_5, hr_10, ndcg_1, ndcg_3, ndcg_5, ndcg_10\n",
    "\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:,['user_id', 'item_id']], ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-tunisia",
   "metadata": {},
   "source": [
    "## Leave-one-out, leave-k-out, cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-spirit",
   "metadata": {},
   "source": [
    "### Explicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-luxembourg",
   "metadata": {},
   "source": [
    "**Task 2.** Implement the following method for leave-one-out evaluation for explicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flexible-runner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MRE</th>\n",
       "      <th>TRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegressionRecommender</td>\n",
       "      <td>1.039763</td>\n",
       "      <td>0.401878</td>\n",
       "      <td>0.240408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_leave_one_out_explicit(recommender, interactions_df, items_df, max_evals=300, seed=6789):\n",
    "    # Write your code here\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "    \n",
    "        \n",
    "    # Prepare splits of the datasets\n",
    "    kf = KFold(n_splits=len(interactions_df), random_state=rng, shuffle=True)\n",
    "    \n",
    "    \n",
    "    # For each split of the dataset train the recommender, generate recommendations and evaluate\n",
    "    \n",
    "    n_eval = 1\n",
    "    r_pred=[]\n",
    "    r_real=[]\n",
    "    for train_index, test_index in kf.split(interactions_df.index):\n",
    "        interactions_df_train = interactions_df.loc[interactions_df.index[train_index]]\n",
    "        interactions_df_test = interactions_df.loc[interactions_df.index[test_index]]\n",
    "                \n",
    "        recommender.fit(interactions_df_train, None, items_df)\n",
    "        \n",
    "        eval_items_df = interactions_df_test['item_id'].to_frame()\n",
    "        \n",
    "        \n",
    "        eval_items_df = pd.merge(eval_items_df, items_df, on='item_id')\n",
    "        \n",
    "        recommendations = recommender.recommend(interactions_df_test.loc[:, ['user_id']], eval_items_df, n_recommendations=1)\n",
    "        \n",
    "        r_pred.append(recommendations.iloc[0]['score'])\n",
    "        r_real.append(interactions_df_test.iloc[0]['rating'])\n",
    "        \n",
    "        if n_eval == max_evals:\n",
    "            break\n",
    "        n_eval += 1\n",
    "    \n",
    "\n",
    "    \n",
    "    return rmse(np.array(r_pred), np.array(r_real)), mre(np.array(r_pred), np.array(r_real)), tre(np.array(r_pred), np.array(r_real))\n",
    "\n",
    "recommender = LinearRegressionRecommender()\n",
    "\n",
    "results = [['LinearRegressionRecommender'] + list(evaluate_leave_one_out_explicit(\n",
    "    recommender, ml_ratings_df, ml_movies_df))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(HTML(results.to_html()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-lloyd",
   "metadata": {},
   "source": [
    "### Implicit feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surrounded-newton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_leave_one_out_implicit(recommender, interactions_df, items_df, max_evals=10, seed=6789):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    # Prepare splits of the datasets\n",
    "    kf = KFold(n_splits=len(interactions_df), random_state=rng, shuffle=True)\n",
    "    \n",
    "    hr_1 = []\n",
    "    hr_3 = []\n",
    "    hr_5 = []\n",
    "    hr_10 = []\n",
    "    ndcg_1 = []\n",
    "    ndcg_3 = []\n",
    "    ndcg_5 = []\n",
    "    ndcg_10 = []\n",
    "    \n",
    "    # For each split of the dataset train the recommender, generate recommendations and evaluate\n",
    "    \n",
    "    n_eval = 1\n",
    "    for train_index, test_index in kf.split(interactions_df.index):\n",
    "        interactions_df_train = interactions_df.loc[interactions_df.index[train_index]]\n",
    "        interactions_df_test = interactions_df.loc[interactions_df.index[test_index]]\n",
    "                \n",
    "        recommender.fit(interactions_df_train, None, items_df)\n",
    "        recommendations = recommender.recommend(interactions_df_test.loc[:, ['user_id']], items_df, n_recommendations=10)\n",
    "        \n",
    "        hr_1.append(hr(recommendations, interactions_df_test, n=1))\n",
    "        hr_3.append(hr(recommendations, interactions_df_test, n=3))\n",
    "        hr_5.append(hr(recommendations, interactions_df_test, n=5))\n",
    "        hr_10.append(hr(recommendations, interactions_df_test, n=10))\n",
    "        ndcg_1.append(ndcg(recommendations, interactions_df_test, n=1))\n",
    "        ndcg_3.append(ndcg(recommendations, interactions_df_test, n=3))\n",
    "        ndcg_5.append(ndcg(recommendations, interactions_df_test, n=5))\n",
    "        ndcg_10.append(ndcg(recommendations, interactions_df_test, n=10))\n",
    "        \n",
    "        if n_eval == max_evals:\n",
    "            break\n",
    "        n_eval += 1\n",
    "        \n",
    "    hr_1 = np.mean(hr_1)\n",
    "    hr_3 = np.mean(hr_3)\n",
    "    hr_5 = np.mean(hr_5)\n",
    "    hr_10 = np.mean(hr_10)\n",
    "    ndcg_1 = np.mean(ndcg_1)\n",
    "    ndcg_3 = np.mean(ndcg_3)\n",
    "    ndcg_5 = np.mean(ndcg_5)\n",
    "    ndcg_10 = np.mean(ndcg_10)\n",
    "    \n",
    "    return hr_1, hr_3, hr_5, hr_10, ndcg_1, ndcg_3, ndcg_5, ndcg_10\n",
    "\n",
    "recommender = Recommender()\n",
    "\n",
    "results = [['BaseRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-chain",
   "metadata": {},
   "source": [
    "# Linear Regression Recommender\n",
    "\n",
    "For every movie we transform its genres into one-hot encoded features and then fit a linear regression model to those features and actual ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sonic-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class LinearRegressionRecommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.mlb = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.split(\"|\")\n",
    "\n",
    "        \n",
    "#         print(interactions_df.head())\n",
    "\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        interactions_df = interactions_df.join(\n",
    "            pd.DataFrame(self.mlb.fit_transform(interactions_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=interactions_df.index))\n",
    "        \n",
    "#         print(interactions_df.head())\n",
    "        \n",
    "        x = interactions_df.loc[:, self.mlb.classes_].values\n",
    "        y = interactions_df['rating'].values\n",
    "    \n",
    "        self.model = LinearRegression().fit(x, y)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform the item to be scored into proper features\n",
    "#         print(items_df)\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        \n",
    "        items_df = items_df.join(\n",
    "            pd.DataFrame(self.mlb.transform(items_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=items_df.index))\n",
    "        \n",
    "#         print(items_df)\n",
    "        \n",
    "        # Score the item\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "#         print(items_df)\n",
    "#         print(items_df.loc[:, self.mlb.classes_].values)\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            score = self.model.predict(items_df.loc[:, self.mlb.classes_].values)[0]\n",
    "                \n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': items_df.iloc[0]['item_id'],\n",
    "                                                 'score': score})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "colored-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating   timestamp                                 title  \\\n",
      "0        1      780     3.0   964984086  Independence Day (a.k.a. ID4) (1996)   \n",
      "1        6      780     5.0   845556915  Independence Day (a.k.a. ID4) (1996)   \n",
      "2        7      780     4.5  1106635943  Independence Day (a.k.a. ID4) (1996)   \n",
      "3       11      780     4.0   902154487  Independence Day (a.k.a. ID4) (1996)   \n",
      "4       15      780     3.5  1510572881  Independence Day (a.k.a. ID4) (1996)   \n",
      "\n",
      "   (no_genres_listed)  action  adventure  animation  children  ...  fantasy  \\\n",
      "0                   0       1          1          0         0  ...        0   \n",
      "1                   0       1          1          0         0  ...        0   \n",
      "2                   0       1          1          0         0  ...        0   \n",
      "3                   0       1          1          0         0  ...        0   \n",
      "4                   0       1          1          0         0  ...        0   \n",
      "\n",
      "   film_noir  horror  musical  mystery  romance  sci_fi  thriller  war  \\\n",
      "0          0       0        0        0        0       1         1    0   \n",
      "1          0       0        0        0        0       1         1    0   \n",
      "2          0       0        0        0        0       1         1    0   \n",
      "3          0       0        0        0        0       1         1    0   \n",
      "4          0       0        0        0        0       1         1    0   \n",
      "\n",
      "   western  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Quick test of the recommender\n",
    "\n",
    "lr_recommender = LinearRegressionRecommender()\n",
    "lr_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "# recommendations = lr_recommender.recommend(pd.DataFrame([[1], [2]], columns=['user_id']), ml_movies_df, 1)\n",
    "\n",
    "# recommendations = pd.merge(recommendations, ml_movies_df, on='item_id')\n",
    "# display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_recommender = LinearRegressionRecommender()\n",
    "\n",
    "results = [['LinearRegressionRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    lr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-mozambique",
   "metadata": {},
   "source": [
    "# TF-IDF Recommender\n",
    "TF-IDF stands for term frequencyâ€“inverse document frequency. Typically Tf-IDF method is used to assign keywords (words describing the gist of a document) to documents in a corpus of documents.\n",
    "\n",
    "In our case we will treat users as documents and genres as words.\n",
    "\n",
    "Term-frequency is given by the following formula:\n",
    "<center>\n",
    "$$\n",
    "    \\text{tf}(g, u) = f_{g, u}\n",
    "$$\n",
    "</center>\n",
    "where $f_{g, i}$ is the number of times genre $g$ appear for movies watched by user $u$.\n",
    "\n",
    "Inverse document frequency is defined as follows:\n",
    "<center>\n",
    "$$\n",
    "    \\text{idf}(g) = \\log \\frac{N}{n_g}\n",
    "$$\n",
    "</center>\n",
    "where $N$ is the number of users and $n_g$ is the number of users with $g$ in their genres list.\n",
    "\n",
    "Finally, tf-idf is defined as follows:\n",
    "<center>\n",
    "$$\n",
    "    \\text{tfidf}(g, u) = \\text{tf}(g, u) \\cdot \\text{idf}(g)\n",
    "$$\n",
    "</center>\n",
    "\n",
    "In our case we will measure how often a given genre appears for movies watched by a given user vs how often it appears for all users. To obtain a movie score we will take the average of its genres' scores for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "infrared-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TFIDFRecommender(object):\n",
    "    \"\"\"\n",
    "    Recommender based on the TF-IDF method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.tfidf_scores = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tfidf_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "        # Prepare the corpus for tfidf calculation\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        user_genres = interactions_df.loc[:, ['user_id', 'genres']]\n",
    "        user_genres.loc[:, 'genres'] = user_genres['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        user_genres.loc[:, 'genres'] = user_genres['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        user_genres = user_genres.groupby('user_id').aggregate(lambda x: \"|\".join(x))\n",
    "        user_genres.loc[:, 'genres'] = user_genres['genres'].str.replace(\"|\", \" \", regex=False)\n",
    "#         print(user_genres)\n",
    "        user_ids = user_genres.index.tolist()\n",
    "        genres_corpus = user_genres['genres'].tolist()\n",
    "        \n",
    "        # Calculate tf-idf scores\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_scores = vectorizer.fit_transform(genres_corpus)\n",
    "        \n",
    "        # Transform results into a dict {(user_id, genre): score}\n",
    "        \n",
    "        for u in range(tfidf_scores.shape[0]):\n",
    "            for g in range(tfidf_scores.shape[1]):\n",
    "                self.tfidf_scores[(user_ids[u], vectorizer.get_feature_names()[g])] = tfidf_scores[u, g]\n",
    "                \n",
    "#         print(self.tfidf_scores)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        # Transform genres to a unified form used by the vectorizer\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "                \n",
    "        # Score items    \n",
    "        \n",
    "        for uix, user in users_df.iterrows():\n",
    "            items = []\n",
    "            for iix, item in items_df.iterrows():\n",
    "                score = 0.0\n",
    "                for genre in item['genres']:\n",
    "                    score += self.tfidf_scores[(user['user_id'], genre)]\n",
    "                score /= len(item['genres'])\n",
    "                items.append((item['item_id'], score))\n",
    "                \n",
    "            items = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': [item[0] for item in items][:n_recommendations],\n",
    "                                                 'score': [item[1] for item in items][:n_recommendations]})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the recommender\n",
    "\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "tfidf_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = tfidf_recommender.recommend(pd.DataFrame([[1], [2]], columns=['user_id']), ml_movies_df, 3)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "qualified-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.042062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:1000, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sexual-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  item_id\n",
      "839        6      780\n",
      "892        7      780\n",
      "216        1     3479\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "     user_id  item_id\n",
      "839        6      780\n",
      "892        7      780\n",
      "216        1     3479\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "     user_id  item_id\n",
      "839        6      780\n",
      "892        7      780\n",
      "216        1     3479\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n",
      "hr  0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:1000, ['user_id', 'item_id']], ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-snapshot",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-maria",
   "metadata": {},
   "source": [
    "**Task 3.** Implement the MostPopularRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strategic-commons",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MostPopularRecommender</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.040079</td>\n",
       "      <td>0.053997</td>\n",
       "      <td>0.079749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code hereclass Recommender(object):\n",
    "class MostPopularRecommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.most_popular=None\n",
    "        \n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        tmp_interactions = interactions_df.groupby('item_id').count().reset_index()\n",
    "        tmp_interactions = tmp_interactions.loc[:,['item_id','user_id']].rename(columns={'user_id':'order'})\n",
    "        self.most_popular = tmp_interactions\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        recommendations = self.most_popular.sort_values(by=['order'],ascending=False).iloc[:n_recommendations]\n",
    "\n",
    "        users_df.loc[:,'key']=1\n",
    "        \n",
    "        recommendations.loc[:,'key']=1\n",
    "\n",
    "        recommendations = recommendations.merge(users_df,on='key').drop('key',1).sort_values(by=['user_id','order'],ascending=False)\n",
    "\n",
    "        \n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "mpr = MostPopularRecommender()\n",
    "\n",
    "results = [['MostPopularRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    mpr, ml_ratings_df.loc[:,['user_id', 'item_id']], ml_movies_df,max_evals=300))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-schedule",
   "metadata": {},
   "source": [
    "**Task 4.** Implement the HighestRatedRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "likely-vatican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighestRatedRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.005912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code hereclass Recommender(object):\n",
    "class HighestRatedRecommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.highest_rate=None\n",
    "        \n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        tmp_interactions = interactions_df.groupby('item_id').max().reset_index()\n",
    "        tmp_interactions = tmp_interactions.loc[:,['item_id','rating']].sort_values(by=['rating'],ascending=False).rename(columns={'rating':'order'})\n",
    "        self.highest_rate = tmp_interactions\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        recommendations = self.highest_rate.iloc[:n_recommendations]\n",
    "        recommendations = recommendations.merge(items_df,on='item_id')\n",
    "        tmp_users_df = users_df.copy()\n",
    "        tmp_users_df.loc[:,'key']=1\n",
    "        recommendations.loc[:,'key']=1\n",
    "        recommendations = recommendations.merge(tmp_users_df,on='key').drop('key',1).sort_values(by=['user_id','order'],ascending=False)\n",
    "        \n",
    "        \n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "hrr = HighestRatedRecommender()\n",
    "\n",
    "results = [['HighestRatedRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    hrr, ml_ratings_df.loc[:,['user_id', 'item_id','rating']], ml_movies_df,max_evals=300))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-palmer",
   "metadata": {},
   "source": [
    "**Task 5.** Implement the RandomRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minute-cliff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RandomRecommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.random=None\n",
    "        self.train=None\n",
    "        \n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "\n",
    "        self.train = interactions_df\n",
    "\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        rng = np.random.RandomState(seed=6789)\n",
    "\n",
    "        tmp_interactions = pd.DataFrame(items_df.loc[:,'item_id'].unique(),columns=['item_id'])\n",
    "        tmp_interactions = tmp_interactions.sample(n=n_recommendations,random_state=rng)\n",
    "\n",
    "        recommendations = tmp_interactions\n",
    "\n",
    "        users_df.loc[:,'key']=1\n",
    "        recommendations.loc[:,'key']=1\n",
    "        recommendations = recommendations.merge(users_df,on='key').drop('key',1)\n",
    "\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "rr = RandomRecommender()\n",
    "\n",
    "\n",
    "results = [['RandomRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    rr, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df,max_evals=300))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-heart",
   "metadata": {},
   "source": [
    "**Task 6.** Gather the results for TFIDFRecommender, MostPopularRecommender, HighestRatedRecommender, RandomRecommender in one DataFrame and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "optical-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.062178</td>\n",
       "      <td>0.096151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MostPopularRecommender</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.463093</td>\n",
       "      <td>0.501778</td>\n",
       "      <td>0.537399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighestRatedRecommender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomRecommender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043068</td>\n",
       "      <td>0.043068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tfidf\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "results_tfidf = [['TFIDFRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results_tfidf = pd.DataFrame(results_tfidf, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "# MOSTPOPULAR\n",
    "\n",
    "mpr = MostPopularRecommender()\n",
    "\n",
    "results_mpr = [['MostPopularRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    mpr, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "results_mpr = pd.DataFrame(results_mpr, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "# hrr\n",
    "hrr = HighestRatedRecommender()\n",
    "\n",
    "results_hrr = [['HighestRatedRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    hrr, ml_ratings_df.loc[:, ['user_id', 'item_id','rating']], ml_movies_df))]\n",
    "\n",
    "results_hrr = pd.DataFrame(results_hrr, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "# rr\n",
    "rr = RandomRecommender()\n",
    "\n",
    "results_rr = [['RandomRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    rr, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "results_rr = pd.DataFrame(results_rr, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "result = pd.concat([results_tfidf,results_mpr,results_hrr,results_rr])\n",
    "display(HTML(result.to_html()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-burlington",
   "metadata": {},
   "source": [
    "**Task 7\\*.** Implement an SVRRecommender - one-hot encode genres and fit an SVR model to \n",
    "\n",
    "(genre_1, genre_2, ..., genre_N) -> rating\n",
    "\n",
    "Tune params of the SVR model to obtain as good results as you can. \n",
    "\n",
    "To do tuning properly (although in practive people are often happy with leave-one-out and do not bother with dividing the set into training, validation and test sets):\n",
    "    - divide the set into training, validation and test sets (randomly divide the dataset in proportions 60%-20%-20%),\n",
    "    - train the model with different sets of tunable parameters on the training set, \n",
    "    - choose the best tunable params based on results on the validation set, \n",
    "    - provide the final evaluation metrics on the test set for the best model obtained during tuning.\n",
    "\n",
    "Recommended method of tuning: use hyperopt. Install the package using the following command: `pip install hyperopt`\n",
    "    \n",
    "Print the RMSE and MAE on the test set generated with numpy with seed 6789."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "promotional-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.10trial/s, best loss: 1.1485344852744395]\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-c2b10195acd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVRRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m results = [['SVRRecommender'] + list(evaluate_train_test_split_explicit(\n\u001b[0m\u001b[1;32m    185\u001b[0m     svr, ml_ratings_df.iloc[:5000], ml_movies_df, seed=6789))]\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-d5944a20f74e>\u001b[0m in \u001b[0;36mevaluate_train_test_split_explicit\u001b[0;34m(recommender, interactions_df, items_df, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0musers_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0meval_items_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0meval_items_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_items_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_items_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_recommendations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hpsklearn import HyperoptEstimator, svr_linear,standard_scaler,min_max_scaler\n",
    "from hyperopt import hp\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class SVRRecommender(object):\n",
    "    \"\"\"\n",
    "    Recommender based on the TF-IDF method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.mlb = None\n",
    "        self.df_train = None\n",
    "        self.df_val = None\n",
    "        self.df_test = None\n",
    "        self.model=None\n",
    "        self.std=None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df,hyperparameters=False):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.genres_score = defaultdict(lambda: 0.0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.split(\"|\")\n",
    "\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        df_train = interactions_df.join(\n",
    "            pd.DataFrame(self.mlb.fit_transform(interactions_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=interactions_df.index))\n",
    "                \n",
    "        \n",
    "        x = df_train.loc[:, self.mlb.classes_].values\n",
    "        y = df_train['rating'].values\n",
    "        \n",
    "\n",
    "\n",
    "        C = hp.pchoice('C',[(0.25,0.1),(0.25,0.01),(0.5,1.0)])\n",
    "        epsilon = hp.pchoice('epsilon',[(0.5,0.1),(0.25,0.01),(0.25,0.001)])\n",
    "        tol=hp.pchoice('tol',[(0.50,1e-3),(0.25,1e-7),(0.25,1e-5)])\n",
    "\n",
    "        hpSVR = HyperoptEstimator(regressor=svr_linear('my_svr',C=C,epsilon=epsilon,tol=tol),max_evals=1000)\n",
    "        \n",
    "\n",
    "        hpSVR.fit(x,y)\n",
    "        self.model = hpSVR\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def validate(self):\n",
    "        \n",
    "        df_val_X=self.df_val.drop('rating',1)\n",
    "        df_val_y=self.df_val.loc[:,'rating']\n",
    "        \n",
    "        print(\"Validation score: \",self.model.score(df_val_X.iloc[:,1:],df_val_y))\n",
    "        \n",
    "    \n",
    "    def recommend(self, test_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform the item to be scored into proper features\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        \n",
    "        items_df = items_df.join(\n",
    "            pd.DataFrame(self.mlb.transform(items_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=items_df.index))\n",
    "        \n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in test_df.iterrows():\n",
    "            score = self.model.predict(items_df.loc[:, self.mlb.classes_].values)[0]\n",
    "                \n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': items_df.iloc[0]['item_id'],\n",
    "                                                 'score': score})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "                \n",
    "    \n",
    "interactions = ml_ratings_df.loc[:,['user_id','item_id','rating']]\n",
    "svr = SVRRecommender()\n",
    "\n",
    "results = [['SVRRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    svr, ml_ratings_df, ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "print(results)\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-tsunami",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
